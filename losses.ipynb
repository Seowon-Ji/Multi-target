{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "losses.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPVRsVUb6ggcken8jnnMwOf",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Seowon-Ji/Multi-target/blob/master/losses.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "46qTqEfSoFgg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn import init\n",
        "import functools\n",
        "import torch.autograd as autograd\n",
        "import numpy as np\n",
        "import torchvision.models as models\n",
        "import util.util as util\n",
        "from util.image_pool import ImagePool\n",
        "from torch.autograd import Variable\n",
        "###############################################################################\n",
        "# Functions\n",
        "###############################################################################\n",
        "\n",
        "class ContentLoss:\n",
        "\tdef __init__(self, loss):\n",
        "\t\tself.criterion = loss\n",
        "\t\t\t\n",
        "\tdef get_loss(self, fakeIm, realIm):\n",
        "\t\treturn self.criterion(fakeIm, realIm)\n",
        "\n",
        "class PerceptualLoss():\n",
        "\t\n",
        "\tdef contentFunc(self):\n",
        "\t\tconv_3_3_layer = 14\n",
        "\t\tcnn = models.vgg19(pretrained=True).features\n",
        "\t\tcnn = cnn.cuda()\n",
        "\t\tmodel = nn.Sequential()\n",
        "\t\tmodel = model.cuda()\n",
        "\t\tfor i,layer in enumerate(list(cnn)):\n",
        "\t\t\tmodel.add_module(str(i),layer)\n",
        "\t\t\tif i == conv_3_3_layer:\n",
        "\t\t\t\tbreak\n",
        "\t\treturn model\n",
        "\t\t\n",
        "\tdef __init__(self, loss):\n",
        "\t\tself.criterion = loss\n",
        "\t\tself.contentFunc = self.contentFunc()\n",
        "\t\t\t\n",
        "\tdef get_loss(self, fakeIm, realIm):\n",
        "\t\tf_fake = self.contentFunc.forward(fakeIm)\n",
        "\t\tf_real = self.contentFunc.forward(realIm)\n",
        "\t\tf_real_no_grad = f_real.detach()\n",
        "\t\tloss = self.criterion(f_fake, f_real_no_grad)\n",
        "\t\treturn loss\n",
        "\t\t\n",
        "class GANLoss(nn.Module):\n",
        "\tdef __init__(\n",
        "\t\t\tself, use_l1=True, target_real_label=1.0,\n",
        "\t\t\ttarget_fake_label=0.0, tensor=torch.FloatTensor):\n",
        "\t\tsuper(GANLoss, self).__init__()\n",
        "\t\tself.real_label = target_real_label\n",
        "\t\tself.fake_label = target_fake_label\n",
        "\t\tself.real_label_var = None\n",
        "\t\tself.fake_label_var = None\n",
        "\t\tself.Tensor = tensor\n",
        "\t\tif use_l1:\n",
        "\t\t\tself.loss = nn.L1Loss()\n",
        "\t\telse:\n",
        "\t\t\tself.loss = nn.BCELoss()\n",
        "\n",
        "\tdef get_target_tensor(self, input, target_is_real):\n",
        "\t\ttarget_tensor = None\n",
        "\t\tif target_is_real:\n",
        "\t\t\tcreate_label = ((self.real_label_var is None) or\n",
        "\t\t\t\t\t\t\t(self.real_label_var.numel() != input.numel()))\n",
        "\t\t\tif create_label:\n",
        "\t\t\t\treal_tensor = self.Tensor(input.size()).fill_(self.real_label)\n",
        "\t\t\t\tself.real_label_var = Variable(real_tensor, requires_grad=False)\n",
        "\t\t\ttarget_tensor = self.real_label_var\n",
        "\t\telse:\n",
        "\t\t\tcreate_label = ((self.fake_label_var is None) or\n",
        "\t\t\t\t\t\t\t(self.fake_label_var.numel() != input.numel()))\n",
        "\t\t\tif create_label:\n",
        "\t\t\t\tfake_tensor = self.Tensor(input.size()).fill_(self.fake_label)\n",
        "\t\t\t\tself.fake_label_var = Variable(fake_tensor, requires_grad=False)\n",
        "\t\t\ttarget_tensor = self.fake_label_var\n",
        "\t\treturn target_tensor\n",
        "\n",
        "\tdef __call__(self, input, target_is_real):\n",
        "\t\ttarget_tensor = self.get_target_tensor(input, target_is_real)\n",
        "\t\treturn self.loss(input, target_tensor)\n",
        "\n",
        "class DiscLoss:\n",
        "\tdef name(self):\n",
        "\t\treturn 'DiscLoss'\n",
        "\n",
        "\tdef __init__(self, opt, tensor):\n",
        "\t\t# self.criterionGAN = GANLoss(use_l1=False, tensor=tensor)\n",
        "\t\tself.criterionGAN = GANLoss(use_l1=True, tensor=tensor)\n",
        "\t\t# self.fake_AB_pool = ImagePool(opt.pool_size)\n",
        "\t\t\n",
        "\tdef get_g_loss(self,net, realA, fakeB):\n",
        "\t\t# First, G(A) should fake the discriminator\n",
        "\t\tpred_fake = net.forward(fakeB)\n",
        "\t\treturn self.criterionGAN(pred_fake, 1)\n",
        "\t\t\n",
        "\tdef get_loss(self, net, realA, fakeB, realB):\n",
        "\t\t# Fake\n",
        "\t\t# stop backprop to the generator by detaching fake_B\n",
        "\t\t# Generated Image Disc Output should be close to zero\n",
        "\t\tself.pred_fake = net.forward(fakeB.detach())\n",
        "\t\tself.loss_D_fake = self.criterionGAN(self.pred_fake, 0)\n",
        "\n",
        "\t\t# Real\n",
        "\t\tself.pred_real = net.forward(realB)\n",
        "\t\tself.loss_D_real = self.criterionGAN(self.pred_real, 1)\n",
        "\n",
        "\t\t# Combined loss\n",
        "\t\tself.loss_D = (self.loss_D_fake + self.loss_D_real) * 0.5\n",
        "\t\treturn self.loss_D\n",
        "\t\t\n",
        "class DiscLossLS(DiscLoss):\n",
        "\tdef name(self):\n",
        "\t\treturn 'DiscLossLS'\n",
        "\n",
        "\tdef __init__(self, opt, tensor):\n",
        "\t\tsuper(DiscLoss, self).__init__(opt, tensor)\n",
        "\t\t# DiscLoss.initialize(self, opt, tensor)\n",
        "\t\tself.criterionGAN = GANLoss(use_l1=True, tensor=tensor)\n",
        "\t\t\n",
        "\tdef get_g_loss(self,net, realA, fakeB):\n",
        "\t\treturn DiscLoss.get_g_loss(self,net, realA, fakeB)\n",
        "\t\t\n",
        "\tdef get_loss(self, net, realA, fakeB, realB):\n",
        "\t\treturn DiscLoss.get_loss(self, net, realA, fakeB, realB)\n",
        "\t\t\n",
        "class DiscLossWGANGP(DiscLossLS):\n",
        "\tdef name(self):\n",
        "\t\treturn 'DiscLossWGAN-GP'\n",
        "\n",
        "\tdef __init__(self, opt, tensor):\n",
        "\t\tsuper(DiscLossWGANGP, self).__init__(opt, tensor)\n",
        "\t\t# DiscLossLS.initialize(self, opt, tensor)\n",
        "\t\tself.LAMBDA = 10\n",
        "\t\t\n",
        "\tdef get_g_loss(self, net, realA, fakeB):\n",
        "\t\t# First, G(A) should fake the discriminator\n",
        "\t\tself.D_fake = net.forward(fakeB)\n",
        "\t\treturn -self.D_fake.mean()\n",
        "\t\t\n",
        "\tdef calc_gradient_penalty(self, netD, real_data, fake_data):\n",
        "\t\talpha = torch.rand(1, 1)\n",
        "\t\talpha = alpha.expand(real_data.size())\n",
        "\t\talpha = alpha.cuda()\n",
        "\n",
        "\t\tinterpolates = alpha * real_data + ((1 - alpha) * fake_data)\n",
        "\n",
        "\t\tinterpolates = interpolates.cuda()\n",
        "\t\tinterpolates = Variable(interpolates, requires_grad=True)\n",
        "\t\t\n",
        "\t\tdisc_interpolates = netD.forward(interpolates)\n",
        "\n",
        "\t\tgradients = autograd.grad(\n",
        "\t\t\toutputs=disc_interpolates, inputs=interpolates, grad_outputs=torch.ones(disc_interpolates.size()).cuda(),\n",
        "\t\t\tcreate_graph=True, retain_graph=True, only_inputs=True\n",
        "\t\t)[0]\n",
        "\n",
        "\t\tgradient_penalty = ((gradients.norm(2, dim=1) - 1) ** 2).mean() * self.LAMBDA\n",
        "\t\treturn gradient_penalty\n",
        "\t\t\n",
        "\tdef get_loss(self, net, realA, fakeB, realB):\n",
        "\t\tself.D_fake = net.forward(fakeB.detach())\n",
        "\t\tself.D_fake = self.D_fake.mean()\n",
        "\t\t\n",
        "\t\t# Real\n",
        "\t\tself.D_real = net.forward(realB)\n",
        "\t\tself.D_real = self.D_real.mean()\n",
        "\t\t# Combined loss\n",
        "\t\tself.loss_D = self.D_fake - self.D_real\n",
        "\t\tgradient_penalty = self.calc_gradient_penalty(net, realB.data, fakeB.data)\n",
        "\t\treturn self.loss_D + gradient_penalty\n",
        "\n",
        "\n",
        "def init_loss(opt, tensor):\n",
        "\t# disc_loss = None\n",
        "\t# content_loss = None\n",
        "\t\n",
        "\t# if opt.model == 'content_gan':\n",
        "\t# \tcontent_loss = PerceptualLoss(nn.MSELoss())\n",
        "\t# \t# content_loss.initialize(nn.MSELoss())\n",
        "\t# elif opt.model == 'pix2pix':\n",
        "\t# \tcontent_loss = ContentLoss(nn.L1Loss())\n",
        "\t# \t# content_loss.initialize(nn.L1Loss())\n",
        "\t# else:\n",
        "\t# \traise ValueError(\"Model [%s] not recognized.\" % opt.model)\n",
        "\t#\n",
        "\t# if opt.gan_type == 'wgan-gp':\n",
        "\t# \tdisc_loss = DiscLossWGANGP(opt, tensor)\n",
        "\t# elif opt.gan_type == 'lsgan':\n",
        "\t# \tdisc_loss = DiscLossLS(opt, tensor)\n",
        "\t# elif opt.gan_type == 'gan':\n",
        "\t# \tdisc_loss = DiscLoss(opt, tensor)\n",
        "\t# else:\n",
        "\t# \traise ValueError(\"GAN [%s] not recognized.\" % opt.gan_type)\n",
        "\t# # disc_loss.initialize(opt, tensor)\n",
        "\t# return disc_loss, content_loss\n",
        "\tcontent_loss = ContentLoss(nn.L1Loss())\n",
        "\tdisc_loss = DiscLoss(opt, tensor)\n",
        "\treturn disc_loss, content_loss"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}