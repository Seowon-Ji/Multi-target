{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "model.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMS2MjI8QfUCCfrWi+v8nDM",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Seowon-Ji/Multi-target/blob/master/model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "56QvZPEAoOTQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "import functools\n",
        "\n",
        "class Encoder(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Encoder, self).__init__()\n",
        "        # Conv1\n",
        "        self.layer1 = nn.Conv2d(3, 32, kernel_size=3, padding=1)\n",
        "        self.layer2 = nn.Sequential(\n",
        "            nn.Conv2d(32, 32, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(32, 32, kernel_size=3, padding=1)\n",
        "        )\n",
        "        self.layer3 = nn.Sequential(\n",
        "            nn.Conv2d(32, 32, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(32, 32, kernel_size=3, padding=1)\n",
        "        )\n",
        "        # Conv2\n",
        "        self.layer5 = nn.Conv2d(32, 64, kernel_size=3, stride=2, padding=1)\n",
        "        self.layer6 = nn.Sequential(\n",
        "            nn.Conv2d(64, 64, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(64, 64, kernel_size=3, padding=1)\n",
        "        )\n",
        "        self.layer7 = nn.Sequential(\n",
        "            nn.Conv2d(64, 64, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(64, 64, kernel_size=3, padding=1)\n",
        "        )\n",
        "        # Conv3\n",
        "        self.layer9 = nn.Conv2d(64, 128, kernel_size=3, stride=2, padding=1)\n",
        "        self.layer10 = nn.Sequential(\n",
        "            nn.Conv2d(128, 128, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(128, 128, kernel_size=3, padding=1)\n",
        "        )\n",
        "        self.layer11 = nn.Sequential(\n",
        "            nn.Conv2d(128, 128, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(128, 128, kernel_size=3, padding=1)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Conv1\n",
        "        x = self.layer1(x)\n",
        "        x = self.layer2(x) + x\n",
        "        x = self.layer3(x) + x\n",
        "        # Conv2\n",
        "        x = self.layer5(x)\n",
        "        x = self.layer6(x) + x\n",
        "        x = self.layer7(x) + x\n",
        "        # Conv3\n",
        "        x = self.layer9(x)\n",
        "        x = self.layer10(x) + x\n",
        "        x = self.layer11(x) + x\n",
        "        return x\n",
        "\n",
        "\n",
        "class Decoder(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Decoder, self).__init__()\n",
        "        # Deconv3\n",
        "        self.layer13 = nn.Sequential(\n",
        "            nn.Conv2d(128, 128, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(128, 128, kernel_size=3, padding=1)\n",
        "        )\n",
        "        self.layer14 = nn.Sequential(\n",
        "            nn.Conv2d(128, 128, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(128, 128, kernel_size=3, padding=1)\n",
        "        )\n",
        "        self.layer16 = nn.ConvTranspose2d(128, 64, kernel_size=4, stride=2, padding=1)\n",
        "        # Deconv2\n",
        "        self.layer17 = nn.Sequential(\n",
        "            nn.Conv2d(64, 64, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(64, 64, kernel_size=3, padding=1)\n",
        "        )\n",
        "        self.layer18 = nn.Sequential(\n",
        "            nn.Conv2d(64, 64, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(64, 64, kernel_size=3, padding=1)\n",
        "        )\n",
        "        self.layer20 = nn.ConvTranspose2d(64, 32, kernel_size=4, stride=2, padding=1)\n",
        "        # Deconv1\n",
        "        self.layer21 = nn.Sequential(\n",
        "            nn.Conv2d(32, 32, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(32, 32, kernel_size=3, padding=1)\n",
        "        )\n",
        "        self.layer22 = nn.Sequential(\n",
        "            nn.Conv2d(32, 32, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(32, 32, kernel_size=3, padding=1)\n",
        "        )\n",
        "        self.layer24 = nn.Conv2d(32, 3, kernel_size=3, padding=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Deconv3\n",
        "        x = self.layer13(x) + x\n",
        "        x = self.layer14(x) + x\n",
        "        x = self.layer16(x)\n",
        "        # Deconv2\n",
        "        x = self.layer17(x) + x\n",
        "        x = self.layer18(x) + x\n",
        "        x = self.layer20(x)\n",
        "        # Deconv1\n",
        "        x = self.layer21(x) + x\n",
        "        x = self.layer22(x) + x\n",
        "        x = self.layer24(x)\n",
        "        return x\n",
        "\n",
        "class Generator(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Generator, self).__init__()\n",
        "        self.encoder_lv1 = Encoder()\n",
        "        self.encoder_lv2 = Encoder()\n",
        "        self.encoder_lv3 = Encoder()\n",
        "        self.encoder_lv4 = Encoder()\n",
        "\n",
        "        self.decoder_lv1 = Decoder()\n",
        "        self.decoder_lv2 = Decoder()\n",
        "        self.decoder_lv3 = Decoder()\n",
        "        self.decoder_lv4 = Decoder()\n",
        "\n",
        "    def forward(self,x):\n",
        "        images_lv1 = x\n",
        "        H = images_lv1.size(2)\n",
        "        W = images_lv1.size(3)\n",
        "\n",
        "        images_lv2_1 = images_lv1[:, :, 0:int(H / 2), :]\n",
        "        images_lv2_2 = images_lv1[:, :, int(H / 2):H, :]\n",
        "        images_lv3_1 = images_lv2_1[:, :, :, 0:int(W / 2)]\n",
        "        images_lv3_2 = images_lv2_1[:, :, :, int(W / 2):W]\n",
        "        images_lv3_3 = images_lv2_2[:, :, :, 0:int(W / 2)]\n",
        "        images_lv3_4 = images_lv2_2[:, :, :, int(W / 2):W]\n",
        "        images_lv4_1 = images_lv3_1[:, :, 0:int(H / 4), :]\n",
        "        images_lv4_2 = images_lv3_1[:, :, int(H / 4):int(H / 2), :]\n",
        "        images_lv4_3 = images_lv3_2[:, :, 0:int(H / 4), :]\n",
        "        images_lv4_4 = images_lv3_2[:, :, int(H / 4):int(H / 2), :]\n",
        "        images_lv4_5 = images_lv3_3[:, :, 0:int(H / 4), :]\n",
        "        images_lv4_6 = images_lv3_3[:, :, int(H / 4):int(H / 2), :]\n",
        "        images_lv4_7 = images_lv3_4[:, :, 0:int(H / 4), :]\n",
        "        images_lv4_8 = images_lv3_4[:, :, int(H / 4):int(H / 2), :]\n",
        "\n",
        "        feature_lv4_1 = self.encoder_lv4(images_lv4_1)\n",
        "        feature_lv4_2 = self.encoder_lv4(images_lv4_2)\n",
        "        feature_lv4_3 = self.encoder_lv4(images_lv4_3)\n",
        "        feature_lv4_4 = self.encoder_lv4(images_lv4_4)\n",
        "        feature_lv4_5 = self.encoder_lv4(images_lv4_5)\n",
        "        feature_lv4_6 = self.encoder_lv4(images_lv4_6)\n",
        "        feature_lv4_7 = self.encoder_lv4(images_lv4_7)\n",
        "        feature_lv4_8 = self.encoder_lv4(images_lv4_8)\n",
        "\n",
        "        feature_lv4_top_left = torch.cat((feature_lv4_1, feature_lv4_2), 2)\n",
        "        feature_lv4_top_right = torch.cat((feature_lv4_3, feature_lv4_4), 2)\n",
        "        feature_lv4_bot_left = torch.cat((feature_lv4_5, feature_lv4_6), 2)\n",
        "        feature_lv4_bot_right = torch.cat((feature_lv4_7, feature_lv4_8), 2)\n",
        "        feature_lv4_top = torch.cat((feature_lv4_top_left, feature_lv4_top_right), 3)\n",
        "        feature_lv4_bot = torch.cat((feature_lv4_bot_left, feature_lv4_bot_right), 3)\n",
        "        feature_lv4 = torch.cat((feature_lv4_top, feature_lv4_bot), 2)\n",
        "\n",
        "        residual_lv4_top_left = self.decoder_lv4(feature_lv4_top_left)\n",
        "        residual_lv4_top_right = self.decoder_lv4(feature_lv4_top_right)\n",
        "        residual_lv4_bot_left = self.decoder_lv4(feature_lv4_bot_left)\n",
        "        residual_lv4_bot_right = self.decoder_lv4(feature_lv4_bot_right)\n",
        "\n",
        "        feature_lv3_1 =  self.encoder_lv3(images_lv3_1 + residual_lv4_top_left)\n",
        "        feature_lv3_2 =  self.encoder_lv3(images_lv3_2 + residual_lv4_top_right)\n",
        "        feature_lv3_3 =  self.encoder_lv3(images_lv3_3 + residual_lv4_bot_left)\n",
        "        feature_lv3_4 =  self.encoder_lv3(images_lv3_4 + residual_lv4_bot_right)\n",
        "        feature_lv3_top = torch.cat((feature_lv3_1, feature_lv3_2), 3) + feature_lv4_top\n",
        "        feature_lv3_bot = torch.cat((feature_lv3_3, feature_lv3_4), 3) + feature_lv4_bot\n",
        "        feature_lv3 = torch.cat((feature_lv3_top, feature_lv3_bot), 2)\n",
        "        residual_lv3_top =  self.decoder_lv3(feature_lv3_top)\n",
        "        residual_lv3_bot =  self.decoder_lv3(feature_lv3_bot)\n",
        "\n",
        "        feature_lv2_1 = self.encoder_lv2(images_lv2_1 + residual_lv3_top)\n",
        "        feature_lv2_2 = self.encoder_lv2(images_lv2_2 + residual_lv3_bot)\n",
        "        feature_lv2 = torch.cat((feature_lv2_1, feature_lv2_2), 2) + feature_lv3\n",
        "        residual_lv2 = self.decoder_lv2(feature_lv2)\n",
        "\n",
        "        feature_lv1 = self.encoder_lv1(images_lv1 + residual_lv2) + feature_lv2\n",
        "        deblur_image = self.decoder_lv1(feature_lv1)\n",
        "\n",
        "        return deblur_image\n",
        "\n",
        "\n",
        "# Defines the PatchGAN discriminator with the specified arguments.\n",
        "class NLayerDiscriminator(nn.Module):\n",
        "    def __init__(self, input_nc=3, ndf=64, n_layers=3, norm_layer=nn.BatchNorm2d, use_sigmoid=False, gpu_ids=[],\n",
        "                 use_parallel=True):\n",
        "        super(NLayerDiscriminator, self).__init__()\n",
        "        self.gpu_ids = gpu_ids\n",
        "        self.use_parallel = use_parallel\n",
        "\n",
        "        if type(norm_layer) == functools.partial:\n",
        "            use_bias = norm_layer.func == nn.InstanceNorm2d\n",
        "        else:\n",
        "            use_bias = norm_layer == nn.InstanceNorm2d\n",
        "\n",
        "        kw = 4\n",
        "        padw = int(np.ceil((kw - 1) / 2))\n",
        "        sequence = [\n",
        "            nn.Conv2d(input_nc, ndf, kernel_size=kw, stride=2, padding=padw),\n",
        "            nn.LeakyReLU(0.2, True)\n",
        "        ]\n",
        "\n",
        "        nf_mult = 1\n",
        "        nf_mult_prev = 1\n",
        "        for n in range(1, n_layers):\n",
        "            nf_mult_prev = nf_mult\n",
        "            nf_mult = min(2 ** n, 8)\n",
        "            sequence += [\n",
        "                nn.Conv2d(ndf * nf_mult_prev, ndf * nf_mult,\n",
        "                          kernel_size=kw, stride=2, padding=padw, bias=use_bias),\n",
        "                norm_layer(ndf * nf_mult),\n",
        "                nn.LeakyReLU(0.2, True)\n",
        "            ]\n",
        "\n",
        "        nf_mult_prev = nf_mult\n",
        "        nf_mult = min(2 ** n_layers, 8)\n",
        "        sequence += [\n",
        "            nn.Conv2d(ndf * nf_mult_prev, ndf * nf_mult, kernel_size=kw, stride=1, padding=padw, bias=use_bias),\n",
        "            norm_layer(ndf * nf_mult),\n",
        "            nn.LeakyReLU(0.2, True)\n",
        "        ]\n",
        "\n",
        "        sequence += [nn.Conv2d(ndf * nf_mult, 1, kernel_size=kw, stride=1, padding=padw)]\n",
        "\n",
        "        if use_sigmoid:\n",
        "            sequence += [nn.Sigmoid()]\n",
        "\n",
        "        self.model = nn.Sequential(*sequence)\n",
        "\n",
        "    def forward(self, input):\n",
        "        if len(self.gpu_ids) and isinstance(input.data, torch.cuda.FloatTensor) and self.use_parallel:\n",
        "            return nn.parallel.data_parallel(self.model, input, self.gpu_ids)\n",
        "        else:\n",
        "            return self.model(input)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}