{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "test.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPlJExOOY3DxEqk+Klsu+ra",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Seowon-Ji/Multi-target/blob/master/test.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FBIQXWRXoXMX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.autograd import Variable\n",
        "from torch.optim.lr_scheduler import StepLR\n",
        "import numpy as np\n",
        "import os\n",
        "import math\n",
        "import argparse\n",
        "import random\n",
        "import model\n",
        "import torchvision\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms, datasets\n",
        "from dataloader import goprodataset\n",
        "import time\n",
        "from tqdm import tqdm\n",
        "\n",
        "from skimage.measure import compare_psnr, compare_ssim\n",
        "from HED import HED\n",
        "\n",
        "parser = argparse.ArgumentParser(description=\"Deep Multi-Patch Hierarchical Network\")\n",
        "parser.add_argument(\"-e\", \"--epochs\", type=int, default=4000)\n",
        "parser.add_argument(\"-se\", \"--start_epoch\", type=int, default=0)\n",
        "parser.add_argument(\"-b\", \"--batchsize\", type=int, default=8)\n",
        "parser.add_argument(\"-s\", \"--imagesize\", type=int, default=256)\n",
        "parser.add_argument(\"-l\", \"--learning_rate\", type=float, default=0.0001)\n",
        "parser.add_argument(\"-g\", \"--gpu\", type=int, default=0)\n",
        "args = parser.parse_args()\n",
        "\n",
        "# Hyper Parameters\n",
        "METHOD = \"DMPHN_1_2_4_8_l1_sobel_005\"\n",
        "LEARNING_RATE = args.learning_rate\n",
        "EPOCHS = args.epochs\n",
        "GPU = args.gpu\n",
        "BATCH_SIZE = args.batchsize\n",
        "IMAGE_SIZE = args.imagesize\n",
        "\n",
        "\n",
        "def save_deblur_images(images, iteration, epoch):\n",
        "    filename_list = './checkpoints/' + METHOD + \"/test/epoch\" + str(epoch)\n",
        "    if not os.path.exists(filename_list):\n",
        "        os.makedirs(filename_list)\n",
        "    filename = './checkpoints/' + METHOD + \"/test/epoch\" + str(epoch) + \"/\" + \"Iter_\" + str(iteration) + \"_deblur.png\"\n",
        "    torchvision.utils.save_image(images, filename)\n",
        "\n",
        "def save_images(images, name):\n",
        "    filename = './test_out/'  + name\n",
        "    torchvision.utils.save_image(images, filename)\n",
        "\n",
        "def weight_init(m):\n",
        "    classname = m.__class__.__name__\n",
        "    if classname.find('Conv') != -1:\n",
        "        n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
        "        m.weight.data.normal_(0.0, 0.5 * math.sqrt(2. / n))\n",
        "        if m.bias is not None:\n",
        "            m.bias.data.zero_()\n",
        "    elif classname.find('BatchNorm') != -1:\n",
        "        m.weight.data.fill_(1)\n",
        "        m.bias.data.zero_()\n",
        "    elif classname.find('Linear') != -1:\n",
        "        n = m.weight.size(1)\n",
        "        m.weight.data.normal_(0, 0.01)\n",
        "        m.bias.data = torch.ones(m.bias.data.size())\n",
        "\n",
        "\n",
        "def main():\n",
        "    hed = HED().cuda(GPU)\n",
        "    print(\"init data folders\")\n",
        "\n",
        "    encoder_lv1 = model.Encoder()\n",
        "    encoder_lv2 = model.Encoder()\n",
        "    encoder_lv3 = model.Encoder()\n",
        "    encoder_lv4 = model.Encoder()\n",
        "\n",
        "    decoder_lv1 = model.Decoder()\n",
        "    decoder_lv2 = model.Decoder()\n",
        "    decoder_lv3 = model.Decoder()\n",
        "    decoder_lv4 = model.Decoder()\n",
        "\n",
        "    encoder_lv1.apply(weight_init).cuda(GPU)\n",
        "    encoder_lv2.apply(weight_init).cuda(GPU)\n",
        "    encoder_lv3.apply(weight_init).cuda(GPU)\n",
        "    encoder_lv4.apply(weight_init).cuda(GPU)\n",
        "\n",
        "    decoder_lv1.apply(weight_init).cuda(GPU)\n",
        "    decoder_lv2.apply(weight_init).cuda(GPU)\n",
        "    decoder_lv3.apply(weight_init).cuda(GPU)\n",
        "    decoder_lv4.apply(weight_init).cuda(GPU)\n",
        "\n",
        "    step_size = 550\n",
        "\n",
        "    encoder_lv1_optim = torch.optim.Adam(encoder_lv1.parameters(), lr=LEARNING_RATE)\n",
        "    encoder_lv1_scheduler = StepLR(encoder_lv1_optim, step_size=step_size, gamma=0.1)\n",
        "    encoder_lv2_optim = torch.optim.Adam(encoder_lv2.parameters(), lr=LEARNING_RATE)\n",
        "    encoder_lv2_scheduler = StepLR(encoder_lv2_optim, step_size=step_size, gamma=0.1)\n",
        "    encoder_lv3_optim = torch.optim.Adam(encoder_lv3.parameters(), lr=LEARNING_RATE)\n",
        "    encoder_lv3_scheduler = StepLR(encoder_lv3_optim, step_size=step_size, gamma=0.1)\n",
        "    encoder_lv4_optim = torch.optim.Adam(encoder_lv4.parameters(), lr=LEARNING_RATE)\n",
        "    encoder_lv4_scheduler = StepLR(encoder_lv4_optim, step_size=step_size, gamma=0.1)\n",
        "\n",
        "    decoder_lv1_optim = torch.optim.Adam(decoder_lv1.parameters(), lr=LEARNING_RATE)\n",
        "    decoder_lv1_scheduler = StepLR(decoder_lv1_optim, step_size=step_size, gamma=0.1)\n",
        "    decoder_lv2_optim = torch.optim.Adam(decoder_lv2.parameters(), lr=LEARNING_RATE)\n",
        "    decoder_lv2_scheduler = StepLR(decoder_lv2_optim, step_size=step_size, gamma=0.1)\n",
        "    decoder_lv3_optim = torch.optim.Adam(decoder_lv3.parameters(), lr=LEARNING_RATE)\n",
        "    decoder_lv3_scheduler = StepLR(decoder_lv3_optim, step_size=step_size, gamma=0.1)\n",
        "    decoder_lv4_optim = torch.optim.Adam(decoder_lv4.parameters(), lr=LEARNING_RATE)\n",
        "    decoder_lv4_scheduler = StepLR(decoder_lv4_optim, step_size=step_size, gamma=0.1)\n",
        "\n",
        "    if os.path.exists(str('./checkpoints/' + METHOD + \"/encoder_lv1.pkl\")):\n",
        "        encoder_lv1.load_state_dict(torch.load(str('./checkpoints/' + METHOD + \"/encoder_lv1.pkl\")))\n",
        "        print(\"load encoder_lv1 success\")\n",
        "    if os.path.exists(str('./checkpoints/' + METHOD + \"/encoder_lv2.pkl\")):\n",
        "        encoder_lv2.load_state_dict(torch.load(str('./checkpoints/' + METHOD + \"/encoder_lv2.pkl\")))\n",
        "        print(\"load encoder_lv2 success\")\n",
        "    if os.path.exists(str('./checkpoints/' + METHOD + \"/encoder_lv3.pkl\")):\n",
        "        encoder_lv3.load_state_dict(torch.load(str('./checkpoints/' + METHOD + \"/encoder_lv3.pkl\")))\n",
        "        print(\"load encoder_lv3 success\")\n",
        "    if os.path.exists(str('./checkpoints/' + METHOD + \"/encoder_lv4.pkl\")):\n",
        "        encoder_lv4.load_state_dict(torch.load(str('./checkpoints/' + METHOD + \"/encoder_lv4.pkl\")))\n",
        "        print(\"load encoder_lv4 success\")\n",
        "\n",
        "    if os.path.exists(str('./checkpoints/' + METHOD + \"/decoder_lv1.pkl\")):\n",
        "        decoder_lv1.load_state_dict(torch.load(str('./checkpoints/' + METHOD + \"/decoder_lv1.pkl\")))\n",
        "        checkpoint = torch.load(str('./checkpoints/' + METHOD + \"/epoch.pkl\"))\n",
        "        print(\"load encoder_lv1 success\")\n",
        "    if os.path.exists(str('./checkpoints/' + METHOD + \"/decoder_lv2.pkl\")):\n",
        "        decoder_lv2.load_state_dict(torch.load(str('./checkpoints/' + METHOD + \"/decoder_lv2.pkl\")))\n",
        "        print(\"load decoder_lv2 success\")\n",
        "    if os.path.exists(str('./checkpoints/' + METHOD + \"/decoder_lv3.pkl\")):\n",
        "        decoder_lv3.load_state_dict(torch.load(str('./checkpoints/' + METHOD + \"/decoder_lv3.pkl\")))\n",
        "        print(\"load decoder_lv3 success\")\n",
        "    if os.path.exists(str('./checkpoints/' + METHOD + \"/decoder_lv4.pkl\")):\n",
        "        decoder_lv4.load_state_dict(torch.load(str('./checkpoints/' + METHOD + \"/decoder_lv4.pkl\")))\n",
        "        print(\"load decoder_lv4 success\")\n",
        "\n",
        "    if os.path.exists(str('./checkpoints/' + METHOD + \"/epoch.pkl\")):\n",
        "        checkpoint = torch.load(str('./checkpoints/' + METHOD + \"/epoch.pkl\"))\n",
        "        args.start_epoch = checkpoint['epoch']\n",
        "        init_epoch = 0\n",
        "        if args.start_epoch >= step_size:\n",
        "            init_epoch = 550\n",
        "        if args.start_epoch >= 2 *step_size:\n",
        "            init_epoch = step_size * 2\n",
        "\n",
        "        encoder_lv1_scheduler.step(init_epoch)\n",
        "        encoder_lv2_scheduler.step(init_epoch)\n",
        "        encoder_lv3_scheduler.step(init_epoch)\n",
        "        encoder_lv4_scheduler.step(init_epoch)\n",
        "\n",
        "        decoder_lv1_scheduler.step(init_epoch)\n",
        "        decoder_lv2_scheduler.step(init_epoch)\n",
        "        decoder_lv3_scheduler.step(init_epoch)\n",
        "        decoder_lv4_scheduler.step(init_epoch)\n",
        "\n",
        "        print(\"load epoch %d success\"%args.start_epoch)\n",
        "\n",
        "    if os.path.exists('./checkpoints/' + METHOD) == False:\n",
        "        os.system('mkdir ./checkpoints/' + METHOD)\n",
        "\n",
        "    epoch = checkpoint['epoch']\n",
        "    encoder_lv1_scheduler.step(epoch)\n",
        "    encoder_lv2_scheduler.step(epoch)\n",
        "    encoder_lv3_scheduler.step(epoch)\n",
        "    encoder_lv4_scheduler.step(epoch)\n",
        "\n",
        "    decoder_lv1_scheduler.step(epoch)\n",
        "    decoder_lv2_scheduler.step(epoch)\n",
        "    decoder_lv3_scheduler.step(epoch)\n",
        "    decoder_lv4_scheduler.step(epoch)\n",
        "\n",
        "    if os.path.exists('./checkpoints/' + METHOD + '/epoch' + str(epoch)) == False:\n",
        "        os.system('mkdir ./checkpoints/' + METHOD + '/epoch' + str(epoch))\n",
        "\n",
        "    if not os.path.exists('./checkpoints/' + METHOD + '/parameter' + '/epoch' + str(epoch)):\n",
        "        os.makedirs('./checkpoints/' + METHOD + '/parameter' + '/epoch' + str(epoch))\n",
        "\n",
        "    print(\"test...\")\n",
        "    test_dataset = goprodataset(\n",
        "        blur_dir='../deblur_data/gopro_reset/test/blur',\n",
        "        sharp_dir='../deblur_data/gopro_reset/test/sharp'\n",
        "    )\n",
        "    test_dataloader = DataLoader(test_dataset, batch_size=1, shuffle=False)\n",
        "    test_time = 0\n",
        "    total_psnr = []\n",
        "    total_ssim = []\n",
        "    images_name = os.listdir('../deblur_data/gopro_reset/test/blur')\n",
        "    for iteration, images in enumerate(tqdm(test_dataloader)):\n",
        "        with torch.no_grad():\n",
        "            start = time.time()\n",
        "            images_lv1 = Variable(images['blur_image'] - 0.5).cuda(GPU)\n",
        "            H = images_lv1.size(2)\n",
        "            W = images_lv1.size(3)\n",
        "            images_lv2_1 = images_lv1[:, :, 0:int(H / 2), :]\n",
        "            images_lv2_2 = images_lv1[:, :, int(H / 2):H, :]\n",
        "            images_lv3_1 = images_lv2_1[:, :, :, 0:int(W / 2)]\n",
        "            images_lv3_2 = images_lv2_1[:, :, :, int(W / 2):W]\n",
        "            images_lv3_3 = images_lv2_2[:, :, :, 0:int(W / 2)]\n",
        "            images_lv3_4 = images_lv2_2[:, :, :, int(W / 2):W]\n",
        "            images_lv4_1 = images_lv3_1[:, :, 0:int(H / 4), :]\n",
        "            images_lv4_2 = images_lv3_1[:, :, int(H / 4):int(H / 2), :]\n",
        "            images_lv4_3 = images_lv3_2[:, :, 0:int(H / 4), :]\n",
        "            images_lv4_4 = images_lv3_2[:, :, int(H / 4):int(H / 2), :]\n",
        "            images_lv4_5 = images_lv3_3[:, :, 0:int(H / 4), :]\n",
        "            images_lv4_6 = images_lv3_3[:, :, int(H / 4):int(H / 2), :]\n",
        "            images_lv4_7 = images_lv3_4[:, :, 0:int(H / 4), :]\n",
        "            images_lv4_8 = images_lv3_4[:, :, int(H / 4):int(H / 2), :]\n",
        "\n",
        "            feature_lv4_1 = encoder_lv4(images_lv4_1)\n",
        "            feature_lv4_2 = encoder_lv4(images_lv4_2)\n",
        "            feature_lv4_3 = encoder_lv4(images_lv4_3)\n",
        "            feature_lv4_4 = encoder_lv4(images_lv4_4)\n",
        "            feature_lv4_5 = encoder_lv4(images_lv4_5)\n",
        "            feature_lv4_6 = encoder_lv4(images_lv4_6)\n",
        "            feature_lv4_7 = encoder_lv4(images_lv4_7)\n",
        "            feature_lv4_8 = encoder_lv4(images_lv4_8)\n",
        "\n",
        "            feature_lv4_top_left = torch.cat((feature_lv4_1, feature_lv4_2), 2)\n",
        "            feature_lv4_top_right = torch.cat((feature_lv4_3, feature_lv4_4), 2)\n",
        "            feature_lv4_bot_left = torch.cat((feature_lv4_5, feature_lv4_6), 2)\n",
        "            feature_lv4_bot_right = torch.cat((feature_lv4_7, feature_lv4_8), 2)\n",
        "\n",
        "            feature_lv4_top = torch.cat((feature_lv4_top_left, feature_lv4_top_right), 3)\n",
        "            feature_lv4_bot = torch.cat((feature_lv4_bot_left, feature_lv4_bot_right), 3)\n",
        "\n",
        "            residual_lv4_top_left = decoder_lv4(feature_lv4_top_left)\n",
        "            residual_lv4_top_right = decoder_lv4(feature_lv4_top_right)\n",
        "            residual_lv4_bot_left = decoder_lv4(feature_lv4_bot_left)\n",
        "            residual_lv4_bot_right = decoder_lv4(feature_lv4_bot_right)\n",
        "\n",
        "            feature_lv3_1 = encoder_lv3(images_lv3_1 + residual_lv4_top_left)\n",
        "            feature_lv3_2 = encoder_lv3(images_lv3_2 + residual_lv4_top_right)\n",
        "            feature_lv3_3 = encoder_lv3(images_lv3_3 + residual_lv4_bot_left)\n",
        "            feature_lv3_4 = encoder_lv3(images_lv3_4 + residual_lv4_bot_right)\n",
        "\n",
        "            feature_lv3_top = torch.cat((feature_lv3_1, feature_lv3_2), 3) + feature_lv4_top\n",
        "            feature_lv3_bot = torch.cat((feature_lv3_3, feature_lv3_4), 3) + feature_lv4_bot\n",
        "            residual_lv3_top = decoder_lv3(feature_lv3_top)\n",
        "            residual_lv3_bot = decoder_lv3(feature_lv3_bot)\n",
        "\n",
        "            feature_lv2_1 = encoder_lv2(images_lv2_1 + residual_lv3_top)\n",
        "            feature_lv2_2 = encoder_lv2(images_lv2_2 + residual_lv3_bot)\n",
        "            feature_lv2 = torch.cat((feature_lv2_1, feature_lv2_2), 2) + torch.cat(\n",
        "                (feature_lv3_top, feature_lv3_bot), 2)\n",
        "            residual_lv2 = decoder_lv2(feature_lv2)\n",
        "\n",
        "            feature_lv1 = encoder_lv1(images_lv1 + residual_lv2) + feature_lv2\n",
        "            deblur_image = decoder_lv1(feature_lv1)\n",
        "            stop = time.time()\n",
        "            test_time += stop - start\n",
        "            # print('RunTime:%.4f' % (stop - start), '  Average Runtime:%.4f' % (test_time / (iteration + 1)))\n",
        "            # save_deblur_images(deblur_image.data + 0.5, iteration, epoch)\n",
        "            save_images(deblur_image.data + 0.5, images_name[iteration])\n",
        "            # numpy array\n",
        "            deblur_image.data = deblur_image.data + 0.5\n",
        "            out_np = deblur_image.cpu().numpy()\n",
        "            rgb_images_np = images['sharp_image'].numpy()\n",
        "            for i in range(deblur_image.size(0)):\n",
        "                index = iteration + i\n",
        "\n",
        "                psnr = compare_psnr(im_true=rgb_images_np[i], im_test=out_np[i])\n",
        "                ssim = (compare_ssim(X=rgb_images_np[i][0], Y=out_np[i][0]) +\n",
        "                        compare_ssim(X=rgb_images_np[i][1], Y=out_np[i][1]) +\n",
        "                        compare_ssim(X=rgb_images_np[i][2], Y=out_np[i][2])) / 3\n",
        "                total_psnr.append(psnr)\n",
        "                total_ssim.append(ssim)\n",
        "\n",
        "    print('RunTime:%.4f' % (stop - start), '  Average Runtime:%.4f' % (test_time / (iteration + 1)))\n",
        "\n",
        "    # average\n",
        "    total_psnr = np.mean(total_psnr)\n",
        "    total_ssim = np.mean(total_ssim)\n",
        "\n",
        "    with open('test_sobel_005_psnr.txt', 'a') as f:\n",
        "        f.write(\"epoch: %d , PSNR: %.4f , SSIM: %.4f \\n\" % (epoch, total_psnr, total_ssim))\n",
        "        f.close()\n",
        "\n",
        "    # Print psnr, ssim\n",
        "    message = '\\t {}: {:.2f}\\t {}: {:.4f}'.format('psnr', total_psnr, 'ssim', total_ssim)\n",
        "    print(message)\n",
        "    print(\"DONE\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}